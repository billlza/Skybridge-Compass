import Foundation
@preconcurrency import ScreenCaptureKit
import VideoToolbox
import CoreVideo
import OSLog
import ImageIO
import UniformTypeIdentifiers

/// ä½¿ç”¨ ScreenCaptureKit æ•è·å±å¹•å¹¶é€šè¿‡ VideoToolbox ç¼–ç ä¸º HEVC/H.264 çš„æ•°æ®æµ
/// - ä¸­æ–‡è¯´æ˜ï¼šè¯¥ç»„ä»¶ä¸“æ³¨äºæœ¬åœ°å±å¹•é‡‡é›†ä¸ç¡¬ä»¶åŠ é€Ÿç¼–ç ï¼Œå¤–éƒ¨é€šè¿‡å›è°ƒæ¥æ”¶å‹ç¼©åçš„è§†é¢‘å¸§æ•°æ®ã€‚
final class ScreenCaptureKitStreamer: NSObject {
    private let logger = Logger(subsystem: "com.skybridge.compass", category: "SCKStreamer")
    private var stream: SCStream?
    private var output: StreamOutput?
    private var compressionSession: VTCompressionSession?
    private var codecType: CMVideoCodecType = kCMVideoCodecType_HEVC
    private var width: Int = 1280
    private var height: Int = 720
    private var started = false
    private var configuredFPS: Int = 60
    private var configuredKeyInterval: Int = 60
    private var preferredProfile: EncodingProfile = .auto
    private var lowLatencyEnabled: Bool = false
    private var jpegMode: Bool = false
    private let sampleOutputQueue = DispatchQueue(
        label: "com.skybridge.compass.sck.output",
        qos: .userInteractive
    )

 /// ç¼–ç åè§†é¢‘å¸§çš„å›è°ƒ
 /// - å‚æ•°è¯´æ˜ï¼šdata ä¸ºå‹ç¼©åæ¯”ç‰¹æµï¼›w/h ä¸ºè§†é¢‘ç»´åº¦ï¼›type ä¸ºå¸§ç±»å‹ï¼ˆh264/hevcï¼‰
    var onEncodedFrame: ((Data, Int, Int, RemoteFrameType) -> Void)?

 /// å¯åŠ¨é‡‡é›†ä¸ç¼–ç 
    @MainActor
    func start(preferredCodec: RemoteFrameType = .hevc, preferredSize: CGSize? = nil, targetFPS: Int = 60, keyFrameInterval: Int = 60) async throws {
        guard !started else { return }
        started = true
        configuredFPS = targetFPS
        configuredKeyInterval = keyFrameInterval
 // è¯»å–ç¼–ç æ¡£ä½ä¸ä½å»¶è¿Ÿè®¾ç½®ï¼ˆä¸»çº¿ç¨‹å®‰å…¨ï¼‰
        let settings = RemoteDesktopSettingsManager.shared.settings
        preferredProfile = settings.displaySettings.encodingProfile
        lowLatencyEnabled = settings.displaySettings.lowLatencyMode

 // é€‰æ‹©æ˜¾ç¤ºå†…å®¹ï¼šé»˜è®¤ä½¿ç”¨ä¸»æ˜¾ç¤ºå™¨
        let content = try await SCShareableContent.current
        guard let display = content.displays.first else {
            logger.error("ScreenCaptureKit æ— å¯ç”¨æ˜¾ç¤ºè®¾å¤‡")
            throw CocoaError(.fileNoSuchFile)
        }
        width = Int(preferredSize?.width ?? CGFloat(display.width))
        height = Int(preferredSize?.height ?? CGFloat(display.height))

        // iOS ç«¯ä¸ºç®€åŒ–è§£ç ï¼šå…è®¸ç”¨ BGRA æ¨¡å¼è¾“å‡º JPEGï¼ˆé¿å… H.264/HEVC NAL å…¼å®¹é—®é¢˜ï¼‰
        jpegMode = (preferredCodec == .bgra)
        if !jpegMode {
            // æ˜ å°„ç¼–ç ç±»å‹
            codecType = (preferredCodec == .h264) ? kCMVideoCodecType_H264 : kCMVideoCodecType_HEVC
        }

 // åˆ›å»ºè¾“å‡ºå¯¹è±¡ä¸æµé…ç½®
        let configuration = SCStreamConfiguration()
        configuration.width = width
        configuration.height = height
        configuration.pixelFormat = kCVPixelFormatType_32BGRA // åŸå§‹å¸§ï¼Œåç»­ç”±VTCompressionSessionè¿›è¡Œå‹ç¼©
        configuration.minimumFrameInterval = CMTime(value: 1, timescale: CMTimeScale(configuredFPS))
        configuration.capturesAudio = false

        output = StreamOutput(owner: self)
        let filter = SCContentFilter(display: display, excludingWindows: [])
        stream = SCStream(filter: filter, configuration: configuration, delegate: nil)
        if !jpegMode {
            try setupCompressionSession(width: width, height: height, codec: codecType)
        }

 // 18.2: guard let å¤„ç† stream output (Requirements 8.2, 8.3)
        guard let streamOutput = output else {
            logger.error("StreamOutput åˆ›å»ºå¤±è´¥")
            throw CocoaError(.featureUnsupported)
        }
        try stream?.addStreamOutput(streamOutput, type: .screen, sampleHandlerQueue: sampleOutputQueue)
        try await stream?.startCapture()
        if jpegMode {
            logger.info("ğŸ¥ ScreenCaptureKit é‡‡é›†å¯åŠ¨ï¼š\(self.width)x\(self.height), codec=JPEG(BGRA)")
        } else {
            logger.info("ğŸ¥ ScreenCaptureKit é‡‡é›†å¯åŠ¨ï¼š\(self.width)x\(self.height), codec=\(preferredCodec == .h264 ? "H.264" : "HEVC")")
        }
    }

 /// åœæ­¢é‡‡é›†ä¸ç¼–ç 
    @MainActor
    func stop() {
        guard started else { return }
        started = false
        stream?.stopCapture()
        stream = nil
        output = nil
        if let cs = compressionSession {
            VTCompressionSessionCompleteFrames(cs, untilPresentationTimeStamp: CMTime.invalid)
            VTCompressionSessionInvalidate(cs)
        }
        compressionSession = nil
        logger.info("ğŸ›‘ ScreenCaptureKit é‡‡é›†å·²åœæ­¢")
    }

    private func setupCompressionSession(width: Int, height: Int, codec: CMVideoCodecType) throws {
        var cs: VTCompressionSession?
        let status = VTCompressionSessionCreate(
            allocator: kCFAllocatorDefault,
            width: Int32(width),
            height: Int32(height),
            codecType: codec,
            encoderSpecification: nil,
            imageBufferAttributes: nil,
            compressedDataAllocator: nil,
            outputCallback: { refcon, sourceFrameRefCon, status, infoFlags, sampleBuffer in
 // 18.2: guard let å¤„ç† refcon å›è°ƒ (Requirements 8.2, 8.3)
                guard status == noErr, let sampleBuffer, let refcon else { return }

 // 19.2: Type C defensive check for Unmanaged pointer (Requirements 9.1, 9.2)
 // The Unmanaged.fromOpaque conversion is inherently unsafe - we add defensive validation
 // Note: fromOpaque doesn't throw, so we rely on the guard above and validation below
                let streamer = Unmanaged<ScreenCaptureKitStreamer>.fromOpaque(refcon).takeUnretainedValue()

 // Validation: verify the object is still valid by reading its state
 // This is a best-effort check - if the object was deallocated, this will crash
 // in DEBUG (which is desired for early detection) rather than silently corrupting data
 // The tautology (started || !started) forces a read without affecting logic
                #if DEBUG
 // In DEBUG, we want to crash early if the pointer is invalid
                _ = streamer.started  // Force read to validate object
                #endif

                streamer.handleCompressedSample(sampleBuffer)
            },
            refcon: UnsafeMutableRawPointer(Unmanaged.passUnretained(self).toOpaque()),
            compressionSessionOut: &cs
        )
        if status != noErr || cs == nil {
            logger.error("VTCompressionSession åˆ›å»ºå¤±è´¥ï¼š\(status)ï¼Œåˆ‡æ¢åˆ° H.264")
 // å›é€€åˆ° H.264
            var cs2: VTCompressionSession?
            let st2 = VTCompressionSessionCreate(
                allocator: kCFAllocatorDefault,
                width: Int32(width),
                height: Int32(height),
                codecType: kCMVideoCodecType_H264,
                encoderSpecification: nil,
                imageBufferAttributes: nil,
                compressedDataAllocator: nil,
                outputCallback: { refcon, sourceFrameRefCon, status, infoFlags, sampleBuffer in
 // 18.2: guard let å¤„ç† refcon å›è°ƒ (Requirements 8.2, 8.3)
                    guard status == noErr, let sampleBuffer, let refcon else { return }

 // 19.2: Type C defensive check for Unmanaged pointer (Requirements 9.1, 9.2)
                    let streamer = Unmanaged<ScreenCaptureKitStreamer>.fromOpaque(refcon).takeUnretainedValue()

                    #if DEBUG
 // In DEBUG, force read to validate object
                    _ = streamer.started
                    #endif

                    streamer.handleCompressedSample(sampleBuffer)
                },
                refcon: UnsafeMutableRawPointer(Unmanaged.passUnretained(self).toOpaque()),
                compressionSessionOut: &cs2
            )
            guard st2 == noErr, let cs2 else { throw CocoaError(.featureUnsupported) }
            compressionSession = cs2
            codecType = kCMVideoCodecType_H264
        } else {
            compressionSession = cs
        }

        guard let cs = compressionSession else { throw CocoaError(.featureUnsupported) }

 // ç¼–ç å‚æ•°ï¼šå®æ—¶ã€ä½å»¶è¿Ÿã€ç›®æ ‡å¸§ç‡
 // æ ¹æ®è®¾ç½®çš„ç¼–ç æ¡£ä½é€‰æ‹© ProfileLevelï¼ˆä½¿ç”¨åœ¨ start ä¸­æ•è·çš„å€¼ï¼‰
        let profile = preferredProfile
        let profileValue: CFString = {
            switch (codecType, profile) {
            case (kCMVideoCodecType_HEVC, .hevcMain): return kVTProfileLevel_HEVC_Main_AutoLevel
            case (kCMVideoCodecType_HEVC, _): return kVTProfileLevel_HEVC_Main_AutoLevel
            case (kCMVideoCodecType_H264, .h264Baseline): return kVTProfileLevel_H264_Baseline_AutoLevel
            case (kCMVideoCodecType_H264, .h264Main): return kVTProfileLevel_H264_Main_AutoLevel
            case (kCMVideoCodecType_H264, .h264High): return kVTProfileLevel_H264_High_AutoLevel
            default: return kVTProfileLevel_H264_High_AutoLevel
            }
        }()
        VTSessionSetProperty(cs, key: kVTCompressionPropertyKey_ProfileLevel, value: profileValue)
        VTSessionSetProperty(cs, key: kVTCompressionPropertyKey_RealTime, value: kCFBooleanTrue)
        VTSessionSetProperty(cs, key: kVTCompressionPropertyKey_ExpectedFrameRate, value: NSNumber(value: configuredFPS))
        VTSessionSetProperty(cs, key: kVTCompressionPropertyKey_AllowFrameReordering, value: kCFBooleanFalse)
 // ä½å»¶è¿Ÿæ¨¡å¼ï¼šç¼©çŸ­å…³é”®å¸§é—´éš”
        let keyInterval = lowLatencyEnabled ? max(10, min(configuredKeyInterval, 30)) : configuredKeyInterval
        VTSessionSetProperty(cs, key: kVTCompressionPropertyKey_MaxKeyFrameInterval, value: NSNumber(value: keyInterval))

 // è‡ªé€‚åº”ç ç‡æ§åˆ¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
 // æ³¨æ„ï¼šè‡ªé€‚åº”ç ç‡å°†åœ¨å¯åŠ¨åå¼‚æ­¥åº”ç”¨ï¼Œé¿å…åœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è®¿é—® MainActor éš”ç¦»çš„å±æ€§
 // å¯ä»¥é€šè¿‡ NetworkQualityAdaptiveBitrateController çš„å›è°ƒåœ¨è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ç ç‡

        VTCompressionSessionPrepareToEncodeFrames(cs)
    }

    private func handleCompressedSample(_ sampleBuffer: CMSampleBuffer) {
        guard let dataBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else { return }
        var lengthAtOffset: Int = 0
        var totalLength: Int = 0
        var dataPointer: UnsafeMutablePointer<Int8>?
        let status = CMBlockBufferGetDataPointer(dataBuffer, atOffset: 0, lengthAtOffsetOut: &lengthAtOffset, totalLengthOut: &totalLength, dataPointerOut: &dataPointer)
        guard status == kCMBlockBufferNoErr, totalLength > 0, let base = dataPointer else { return }
        let data = Data(bytes: base, count: totalLength)
        let type: RemoteFrameType = (codecType == kCMVideoCodecType_HEVC) ? .hevc : .h264
        onEncodedFrame?(data, width, height, type)
    }

    private func handleJPEGPixelBuffer(_ pixelBuffer: CVPixelBuffer) {
        var cgImage: CGImage?
        let status = VTCreateCGImageFromCVPixelBuffer(pixelBuffer, options: nil, imageOut: &cgImage)
        guard status == noErr, let cgImage else { return }

        let mutable = NSMutableData()
        guard let dest = CGImageDestinationCreateWithData(mutable, UTType.jpeg.identifier as CFString, 1, nil) else { return }
        let props: [CFString: Any] = [
            kCGImageDestinationLossyCompressionQuality: 0.65
        ]
        CGImageDestinationAddImage(dest, cgImage, props as CFDictionary)
        guard CGImageDestinationFinalize(dest) else { return }

        // å¤ç”¨ onEncodedFrameï¼šframeType ç”¨ .bgra æ ‡è®°â€œé H26xâ€ï¼Œä¸Šå±‚å¯æŒ‰ magic åˆ¤æ–­æ˜¯å¦ JPEG
        onEncodedFrame?(mutable as Data, CVPixelBufferGetWidth(pixelBuffer), CVPixelBufferGetHeight(pixelBuffer), .bgra)
    }

 /// SCStream è¾“å‡ºæ¡¥æ¥
 /// 18.2: guard let å¤„ç† stream output (Requirements 8.2, 8.3)
    private final class StreamOutput: NSObject, SCStreamOutput {
        weak var owner: ScreenCaptureKitStreamer?
        init(owner: ScreenCaptureKitStreamer) { self.owner = owner }

        func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of outputType: SCStreamOutputType) {
 // guard let å¤„ç† owner å’Œ compressionSession
            guard let owner = owner else { return }
 // guard let å¤„ç† pixelBuffer (å¤–éƒ¨è¾“å…¥)
            guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

            // JPEG æ¨¡å¼ï¼šç›´æ¥æŠŠ pixelBuffer è½¬æˆ JPEGï¼Œå›è°ƒå‡ºå»
            if owner.jpegMode {
                owner.handleJPEGPixelBuffer(pixelBuffer)
                return
            }

            guard let cs = owner.compressionSession else { return }
            var flags = VTEncodeInfoFlags()
            let pts = CMTime(value: CMTimeValue(Date().timeIntervalSince1970 * 1000), timescale: 1000)
            VTCompressionSessionEncodeFrame(cs, imageBuffer: pixelBuffer, presentationTimeStamp: pts, duration: CMTime.zero, frameProperties: nil, sourceFrameRefcon: nil, infoFlagsOut: &flags)
        }
    }
}
